mlos_bench.optimizers.mlos_core_optimizer
=========================================

.. py:module:: mlos_bench.optimizers.mlos_core_optimizer

.. autoapi-nested-parse::

   A wrapper for mlos_core optimizers for mlos_bench.



Classes
-------

.. autoapisummary::

   mlos_bench.optimizers.mlos_core_optimizer.MlosCoreOptimizer


Module Contents
---------------

.. py:class:: MlosCoreOptimizer(tunables: mlos_bench.tunables.tunable_groups.TunableGroups, config: dict, global_config: Optional[dict] = None, service: Optional[mlos_bench.services.base_service.Service] = None)

   Bases: :py:obj:`mlos_bench.optimizers.base_optimizer.Optimizer`


   A wrapper class for the mlos_core optimizers.

   Create a new optimizer for the given configuration space defined by the
   tunables.

   :param tunables: The tunables to optimize.
   :type tunables: TunableGroups
   :param config: Free-format key/value pairs of configuration parameters to pass to the optimizer.
   :type config: dict
   :param global_config:
   :type global_config: Optional[dict]
   :param service:
   :type service: Optional[Service]


   .. py:method:: __exit__(ex_type: Optional[Type[BaseException]], ex_val: Optional[BaseException], ex_tb: Optional[types.TracebackType]) -> Literal[False]

      Exit the context of the optimizer.



   .. py:method:: bulk_register(configs: Sequence[dict], scores: Sequence[Optional[Dict[str, mlos_bench.tunables.tunable.TunableValue]]], status: Optional[Sequence[mlos_bench.environments.status.Status]] = None) -> bool

      Pre-load the optimizer with the bulk data from previous experiments.

      :param configs: Records of tunable values from other experiments.
      :type configs: Sequence[dict]
      :param scores: Benchmark results from experiments that correspond to `configs`.
      :type scores: Sequence[Optional[Dict[str, TunableValue]]]
      :param status: Status of the experiments that correspond to `configs`.
      :type status: Optional[Sequence[Status]]

      :returns: **is_not_empty** -- True if there is data to register, false otherwise.
      :rtype: bool



   .. py:method:: get_best_observation() -> Union[Tuple[Dict[str, float], mlos_bench.tunables.tunable_groups.TunableGroups], Tuple[None, None]]

      Get the best observation so far.

      :returns: **(value, tunables)** -- The best value and the corresponding configuration.
                (None, None) if no successful observation has been registered yet.
      :rtype: Tuple[Dict[str, float], TunableGroups]



   .. py:method:: register(tunables: mlos_bench.tunables.tunable_groups.TunableGroups, status: mlos_bench.environments.status.Status, score: Optional[Dict[str, mlos_bench.tunables.tunable.TunableValue]] = None) -> Optional[Dict[str, float]]

      Register the observation for the given configuration.

      :param tunables: The configuration that has been benchmarked.
                       Usually it's the same config that the `.suggest()` method returned.
      :type tunables: TunableGroups
      :param status: Final status of the experiment (e.g., SUCCEEDED or FAILED).
      :type status: Status
      :param score: A dict with the final benchmark results.
                    None if the experiment was not successful.
      :type score: Optional[Dict[str, TunableValue]]

      :returns: **value** -- Benchmark scores extracted (and possibly transformed)
                from the dataframe that's being MINIMIZED.
      :rtype: Optional[Dict[str, float]]



   .. py:method:: suggest() -> mlos_bench.tunables.tunable_groups.TunableGroups

      Generate the next suggestion. Base class' implementation increments the
      iteration count and returns the current values of the tunables.

      :returns: **tunables** -- The next configuration to benchmark.
                These are the same tunables we pass to the constructor,
                but with the values set to the next suggestion.
      :rtype: TunableGroups



   .. py:property:: name
      :type: str


      The name of the optimizer.

      We save this information in mlos_bench storage to track the source of each
      configuration.


