mlos_bench.optimizers.mock_optimizer
====================================

.. py:module:: mlos_bench.optimizers.mock_optimizer

.. autoapi-nested-parse::

   Mock optimizer for mlos_bench.



Classes
-------

.. autoapisummary::

   mlos_bench.optimizers.mock_optimizer.MockOptimizer


Module Contents
---------------

.. py:class:: MockOptimizer(tunables: mlos_bench.tunables.tunable_groups.TunableGroups, config: dict, global_config: Optional[dict] = None, service: Optional[mlos_bench.services.base_service.Service] = None)

   Bases: :py:obj:`mlos_bench.optimizers.track_best_optimizer.TrackBestOptimizer`


   Mock optimizer to test the Environment API.

   Create a new optimizer for the given configuration space defined by the
   tunables.

   :param tunables: The tunables to optimize.
   :type tunables: TunableGroups
   :param config: Free-format key/value pairs of configuration parameters to pass to the optimizer.
   :type config: dict
   :param global_config:
   :type global_config: Optional[dict]
   :param service:
   :type service: Optional[Service]


   .. py:method:: bulk_register(configs: Sequence[dict], scores: Sequence[Optional[Dict[str, mlos_bench.tunables.tunable.TunableValue]]], status: Optional[Sequence[mlos_bench.environments.status.Status]] = None) -> bool

      Pre-load the optimizer with the bulk data from previous experiments.

      :param configs: Records of tunable values from other experiments.
      :type configs: Sequence[dict]
      :param scores: Benchmark results from experiments that correspond to `configs`.
      :type scores: Sequence[Optional[Dict[str, TunableValue]]]
      :param status: Status of the experiments that correspond to `configs`.
      :type status: Optional[Sequence[Status]]

      :returns: **is_not_empty** -- True if there is data to register, false otherwise.
      :rtype: bool



   .. py:method:: suggest() -> mlos_bench.tunables.tunable_groups.TunableGroups

      Generate the next (random) suggestion.



