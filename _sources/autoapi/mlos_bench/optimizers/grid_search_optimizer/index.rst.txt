mlos_bench.optimizers.grid_search_optimizer
===========================================

.. py:module:: mlos_bench.optimizers.grid_search_optimizer

.. autoapi-nested-parse::

   Grid search optimizer for mlos_bench.



Classes
-------

.. autoapisummary::

   mlos_bench.optimizers.grid_search_optimizer.GridSearchOptimizer


Module Contents
---------------

.. py:class:: GridSearchOptimizer(tunables: mlos_bench.tunables.tunable_groups.TunableGroups, config: dict, global_config: Optional[dict] = None, service: Optional[mlos_bench.services.base_service.Service] = None)

   Bases: :py:obj:`mlos_bench.optimizers.track_best_optimizer.TrackBestOptimizer`


   Grid search optimizer.

   Create a new optimizer for the given configuration space defined by the
   tunables.

   :param tunables: The tunables to optimize.
   :type tunables: TunableGroups
   :param config: Free-format key/value pairs of configuration parameters to pass to the optimizer.
   :type config: dict
   :param global_config:
   :type global_config: Optional[dict]
   :param service:
   :type service: Optional[Service]


   .. py:method:: bulk_register(configs: Sequence[dict], scores: Sequence[Optional[Dict[str, mlos_bench.tunables.tunable.TunableValue]]], status: Optional[Sequence[mlos_bench.environments.status.Status]] = None) -> bool

      Pre-load the optimizer with the bulk data from previous experiments.

      :param configs: Records of tunable values from other experiments.
      :type configs: Sequence[dict]
      :param scores: Benchmark results from experiments that correspond to `configs`.
      :type scores: Sequence[Optional[Dict[str, TunableValue]]]
      :param status: Status of the experiments that correspond to `configs`.
      :type status: Optional[Sequence[Status]]

      :returns: **is_not_empty** -- True if there is data to register, false otherwise.
      :rtype: bool



   .. py:method:: not_converged() -> bool

      Return True if not converged, False otherwise.

      Base implementation just checks the iteration count.



   .. py:method:: register(tunables: mlos_bench.tunables.tunable_groups.TunableGroups, status: mlos_bench.environments.status.Status, score: Optional[Dict[str, mlos_bench.tunables.tunable.TunableValue]] = None) -> Optional[Dict[str, float]]

      Register the observation for the given configuration.

      :param tunables: The configuration that has been benchmarked.
                       Usually it's the same config that the `.suggest()` method returned.
      :type tunables: TunableGroups
      :param status: Final status of the experiment (e.g., SUCCEEDED or FAILED).
      :type status: Status
      :param score: A dict with the final benchmark results.
                    None if the experiment was not successful.
      :type score: Optional[Dict[str, TunableValue]]

      :returns: **value** -- Benchmark scores extracted (and possibly transformed)
                from the dataframe that's being MINIMIZED.
      :rtype: Optional[Dict[str, float]]



   .. py:method:: suggest() -> mlos_bench.tunables.tunable_groups.TunableGroups

      Generate the next grid search suggestion.



   .. py:property:: pending_configs
      :type: Iterable[Dict[str, mlos_bench.tunables.tunable.TunableValue]]


      Gets the set of pending configs in this grid search optimizer.

      :rtype: Iterable[Dict[str, TunableValue]]


   .. py:property:: suggested_configs
      :type: Iterable[Dict[str, mlos_bench.tunables.tunable.TunableValue]]


      Gets the set of configs that have been suggested but not yet registered.

      :rtype: Iterable[Dict[str, TunableValue]]


