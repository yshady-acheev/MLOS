<!DOCTYPE html>
<html class="writer-html5" lang="en" >
<head>
  <meta charset="utf-8" /><meta name="generator" content="Docutils 0.18.1: http://docutils.sourceforge.net/" />

  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  <title>mlos_core.optimizers package &mdash; MlosCore 0.1.dev1+g1307e9a documentation</title>
      <link rel="stylesheet" href="../../_static/pygments.css" type="text/css" />
      <link rel="stylesheet" href="../../_static/css/theme.css" type="text/css" />
      <link rel="stylesheet" href="../../_static/plot_directive.css" type="text/css" />
  <!--[if lt IE 9]>
    <script src="../../_static/js/html5shiv.min.js"></script>
  <![endif]-->
  
        <script src="../../_static/documentation_options.js?v=d96bebca"></script>
        <script src="../../_static/doctools.js?v=888ff710"></script>
        <script src="../../_static/sphinx_highlight.js?v=dc90522c"></script>
        <script crossorigin="anonymous" integrity="sha256-Ae2Vz/4ePdIu6ZyI/5ZGsYnb+m0JlOmKPjt6XZ9JJkA=" src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.4/require.min.js"></script>
    <script src="../../_static/js/theme.js"></script>
    <link rel="index" title="Index" href="../../genindex.html" />
    <link rel="search" title="Search" href="../../search.html" />
    <link rel="next" title="mlos_core.optimizers.bayesian_optimizers package" href="mlos_core.optimizers.bayesian_optimizers.html" />
    <link rel="prev" title="mlos_core package" href="mlos_core.html" /> 
</head>

<body class="wy-body-for-nav"> 
  <div class="wy-grid-for-nav">
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search" >

          
          
          <a href="../../index.html" class="icon icon-home">
            MlosCore
          </a>
              <div class="version">
                0.1.dev1+g1307e9a
              </div>
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="../../search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" aria-label="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>
        </div><div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="Navigation menu">
              <p class="caption" role="heading"><span class="caption-text">Documentation</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../installation.html">Installation</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../overview.html">mlos-core API</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../overview.html#mlos-bench-api">mlos-bench API</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">API Reference</span></p>
<ul class="current">
<li class="toctree-l1 current"><a class="reference internal" href="modules.html">mlos_core</a><ul class="current">
<li class="toctree-l2 current"><a class="reference internal" href="mlos_core.html">mlos_core package</a><ul class="current">
<li class="toctree-l3"><a class="reference internal" href="mlos_core.html#mlos_core.config_to_dataframe"><code class="docutils literal notranslate"><span class="pre">config_to_dataframe()</span></code></a></li>
<li class="toctree-l3 current"><a class="reference internal" href="mlos_core.html#subpackages">Subpackages</a><ul class="current">
<li class="toctree-l4 current"><a class="current reference internal" href="#">mlos_core.optimizers package</a></li>
<li class="toctree-l4"><a class="reference internal" href="mlos_core.spaces.html">mlos_core.spaces package</a></li>
<li class="toctree-l4"><a class="reference internal" href="mlos_core.tests.html">mlos_core.tests package</a></li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../mlos_bench/modules.html">mlos_bench</a></li>
</ul>

        </div>
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap"><nav class="wy-nav-top" aria-label="Mobile navigation menu" >
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="../../index.html">MlosCore</a>
      </nav>

      <div class="wy-nav-content">
        <div class="rst-content">
          <div role="navigation" aria-label="Page navigation">
  <ul class="wy-breadcrumbs">
      <li><a href="../../index.html" class="icon icon-home" aria-label="Home"></a></li>
          <li class="breadcrumb-item"><a href="modules.html">mlos_core</a></li>
          <li class="breadcrumb-item"><a href="mlos_core.html">mlos_core package</a></li>
      <li class="breadcrumb-item active">mlos_core.optimizers package</li>
      <li class="wy-breadcrumbs-aside">
            <a href="../../_sources/api/mlos_core/mlos_core.optimizers.rst.txt" rel="nofollow"> View page source</a>
      </li>
  </ul>
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
             
  <section id="module-mlos_core.optimizers">
<span id="mlos-core-optimizers-package"></span><h1>mlos_core.optimizers package<a class="headerlink" href="#module-mlos_core.optimizers" title="Link to this heading">¶</a></h1>
<p>Basic initializer module for the mlos_core optimizers.</p>
<dl class="py class">
<dt class="sig sig-object py" id="mlos_core.optimizers.BaseOptimizer">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">mlos_core.optimizers.</span></span><span class="sig-name descname"><span class="pre">BaseOptimizer</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="o"><span class="pre">*</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">parameter_space</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">ConfigurationSpace</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">space_adapter</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><a class="reference internal" href="../../generated/mlos_core.spaces.adapters.adapter.BaseSpaceAdapter.html#mlos_core.spaces.adapters.adapter.BaseSpaceAdapter" title="mlos_core.spaces.adapters.adapter.BaseSpaceAdapter"><span class="pre">BaseSpaceAdapter</span></a><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><span class="pre">None</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#mlos_core.optimizers.BaseOptimizer" title="Link to this definition">¶</a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">object</span></code></p>
<p>Optimizer abstract base class defining the basic interface.</p>
<dl class="field-list simple">
<dt class="field-odd">Attributes<span class="colon">:</span></dt>
<dd class="field-odd"><dl class="simple">
<dt><a class="reference internal" href="#mlos_core.optimizers.BaseOptimizer.space_adapter" title="mlos_core.optimizers.BaseOptimizer.space_adapter"><code class="xref py py-obj docutils literal notranslate"><span class="pre">space_adapter</span></code></a></dt><dd><p>Get the space adapter instance (if any).</p>
</dd>
</dl>
</dd>
</dl>
<p class="rubric">Methods</p>
<table class="autosummary longtable docutils align-default">
<tbody>
<tr class="row-odd"><td><p><a class="reference internal" href="#mlos_core.optimizers.BaseOptimizer.cleanup" title="mlos_core.optimizers.BaseOptimizer.cleanup"><code class="xref py py-obj docutils literal notranslate"><span class="pre">cleanup</span></code></a>()</p></td>
<td><p>Cleanup the optimizer.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#mlos_core.optimizers.BaseOptimizer.get_best_observation" title="mlos_core.optimizers.BaseOptimizer.get_best_observation"><code class="xref py py-obj docutils literal notranslate"><span class="pre">get_best_observation</span></code></a>()</p></td>
<td><p>Returns the best observation so far as a dataframe.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#mlos_core.optimizers.BaseOptimizer.get_observations" title="mlos_core.optimizers.BaseOptimizer.get_observations"><code class="xref py py-obj docutils literal notranslate"><span class="pre">get_observations</span></code></a>()</p></td>
<td><p>Returns the observations as a dataframe.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#mlos_core.optimizers.BaseOptimizer.register" title="mlos_core.optimizers.BaseOptimizer.register"><code class="xref py py-obj docutils literal notranslate"><span class="pre">register</span></code></a>(configurations, scores[, context])</p></td>
<td><p>Wrapper method, which employs the space adapter (if any), before registering the configurations and scores.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#mlos_core.optimizers.BaseOptimizer.register_pending" title="mlos_core.optimizers.BaseOptimizer.register_pending"><code class="xref py py-obj docutils literal notranslate"><span class="pre">register_pending</span></code></a>(configurations[, context])</p></td>
<td><p>Registers the given configurations as &quot;pending&quot;.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#mlos_core.optimizers.BaseOptimizer.suggest" title="mlos_core.optimizers.BaseOptimizer.suggest"><code class="xref py py-obj docutils literal notranslate"><span class="pre">suggest</span></code></a>([context, defaults])</p></td>
<td><p>Wrapper method, which employs the space adapter (if any), after suggesting a new configuration.</p></td>
</tr>
</tbody>
</table>
<dl class="py method">
<dt class="sig sig-object py" id="mlos_core.optimizers.BaseOptimizer.cleanup">
<span class="sig-name descname"><span class="pre">cleanup</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">None</span></span></span><a class="headerlink" href="#mlos_core.optimizers.BaseOptimizer.cleanup" title="Link to this definition">¶</a></dt>
<dd><p>Cleanup the optimizer.</p>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="mlos_core.optimizers.BaseOptimizer.get_best_observation">
<span class="sig-name descname"><span class="pre">get_best_observation</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">DataFrame</span></span></span><a class="headerlink" href="#mlos_core.optimizers.BaseOptimizer.get_best_observation" title="Link to this definition">¶</a></dt>
<dd><p>Returns the best observation so far as a dataframe.</p>
<dl class="field-list simple">
<dt class="field-odd">Returns<span class="colon">:</span></dt>
<dd class="field-odd"><dl class="simple">
<dt><strong>best_observation</strong><span class="classifier">pd.DataFrame</span></dt><dd><p>Dataframe with a single row containing the best observation. The columns are parameter names and “score” for the score.</p>
</dd>
</dl>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="mlos_core.optimizers.BaseOptimizer.get_observations">
<span class="sig-name descname"><span class="pre">get_observations</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">DataFrame</span></span></span><a class="headerlink" href="#mlos_core.optimizers.BaseOptimizer.get_observations" title="Link to this definition">¶</a></dt>
<dd><p>Returns the observations as a dataframe.</p>
<dl class="field-list simple">
<dt class="field-odd">Returns<span class="colon">:</span></dt>
<dd class="field-odd"><dl class="simple">
<dt><strong>observations</strong><span class="classifier">pd.DataFrame</span></dt><dd><p>Dataframe of observations. The columns are parameter names and “score” for the score, each row is an observation.</p>
</dd>
</dl>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="mlos_core.optimizers.BaseOptimizer.register">
<span class="sig-name descname"><span class="pre">register</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">configurations</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">DataFrame</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">scores</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Series</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">context</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">DataFrame</span><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><span class="pre">None</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">None</span></span></span><a class="headerlink" href="#mlos_core.optimizers.BaseOptimizer.register" title="Link to this definition">¶</a></dt>
<dd><p>Wrapper method, which employs the space adapter (if any), before registering the configurations and scores.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><dl class="simple">
<dt><strong>configurations</strong><span class="classifier">pd.DataFrame</span></dt><dd><p>Dataframe of configurations / parameters. The columns are parameter names and the rows are the configurations.</p>
</dd>
<dt><strong>scores</strong><span class="classifier">pd.Series</span></dt><dd><p>Scores from running the configurations. The index is the same as the index of the configurations.</p>
</dd>
<dt><strong>context</strong><span class="classifier">pd.DataFrame</span></dt><dd><p>Not Yet Implemented.</p>
</dd>
</dl>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="mlos_core.optimizers.BaseOptimizer.register_pending">
<em class="property"><span class="pre">abstract</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">register_pending</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">configurations</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">DataFrame</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">context</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">DataFrame</span><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><span class="pre">None</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">None</span></span></span><a class="headerlink" href="#mlos_core.optimizers.BaseOptimizer.register_pending" title="Link to this definition">¶</a></dt>
<dd><p>Registers the given configurations as “pending”.
That is it say, it has been suggested by the optimizer, and an experiment trial has been started.
This can be useful for executing multiple trials in parallel, retry logic, etc.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><dl class="simple">
<dt><strong>configurations</strong><span class="classifier">pd.DataFrame</span></dt><dd><p>Dataframe of configurations / parameters. The columns are parameter names and the rows are the configurations.</p>
</dd>
<dt><strong>context</strong><span class="classifier">pd.DataFrame</span></dt><dd><p>Not Yet Implemented.</p>
</dd>
</dl>
</dd>
</dl>
</dd></dl>

<dl class="py property">
<dt class="sig sig-object py" id="mlos_core.optimizers.BaseOptimizer.space_adapter">
<em class="property"><span class="pre">property</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">space_adapter</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><a class="reference internal" href="../../generated/mlos_core.spaces.adapters.adapter.BaseSpaceAdapter.html#mlos_core.spaces.adapters.adapter.BaseSpaceAdapter" title="mlos_core.spaces.adapters.adapter.BaseSpaceAdapter"><span class="pre">BaseSpaceAdapter</span></a><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><span class="pre">None</span></em><a class="headerlink" href="#mlos_core.optimizers.BaseOptimizer.space_adapter" title="Link to this definition">¶</a></dt>
<dd><p>Get the space adapter instance (if any).</p>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="mlos_core.optimizers.BaseOptimizer.suggest">
<span class="sig-name descname"><span class="pre">suggest</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">context</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">DataFrame</span><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><span class="pre">None</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">defaults</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">bool</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">False</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">DataFrame</span></span></span><a class="headerlink" href="#mlos_core.optimizers.BaseOptimizer.suggest" title="Link to this definition">¶</a></dt>
<dd><p>Wrapper method, which employs the space adapter (if any), after suggesting a new configuration.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><dl class="simple">
<dt><strong>context</strong><span class="classifier">pd.DataFrame</span></dt><dd><p>Not Yet Implemented.</p>
</dd>
<dt><strong>defaults</strong><span class="classifier">bool</span></dt><dd><p>Whether or not to return the default config instead of an optimizer guided one.
By default, use the one from the optimizer.</p>
</dd>
</dl>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><dl class="simple">
<dt><strong>configuration</strong><span class="classifier">pd.DataFrame</span></dt><dd><p>Pandas dataframe with a single row. Column names are the parameter names.</p>
</dd>
</dl>
</dd>
</dl>
</dd></dl>

</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="mlos_core.optimizers.FlamlOptimizer">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">mlos_core.optimizers.</span></span><span class="sig-name descname"><span class="pre">FlamlOptimizer</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="o"><span class="pre">*</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">parameter_space</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">ConfigurationSpace</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">space_adapter</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><a class="reference internal" href="../../generated/mlos_core.spaces.adapters.adapter.BaseSpaceAdapter.html#mlos_core.spaces.adapters.adapter.BaseSpaceAdapter" title="mlos_core.spaces.adapters.adapter.BaseSpaceAdapter"><span class="pre">BaseSpaceAdapter</span></a><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><span class="pre">None</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">low_cost_partial_config</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">dict</span><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><span class="pre">None</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">seed</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">int</span><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><span class="pre">None</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#mlos_core.optimizers.FlamlOptimizer" title="Link to this definition">¶</a></dt>
<dd><p>Bases: <a class="reference internal" href="../../generated/mlos_core.optimizers.optimizer.BaseOptimizer.html#mlos_core.optimizers.optimizer.BaseOptimizer" title="mlos_core.optimizers.optimizer.BaseOptimizer"><code class="xref py py-class docutils literal notranslate"><span class="pre">BaseOptimizer</span></code></a></p>
<p>Wrapper class for FLAML Optimizer: A fast library for AutoML and tuning.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><dl class="simple">
<dt><strong>parameter_space</strong><span class="classifier">ConfigSpace.ConfigurationSpace</span></dt><dd><p>The parameter space to optimize.</p>
</dd>
<dt><strong>space_adapter</strong><span class="classifier">BaseSpaceAdapter</span></dt><dd><p>The space adapter class to employ for parameter space transformations.</p>
</dd>
<dt><strong>low_cost_partial_config</strong><span class="classifier">dict</span></dt><dd><p>A dictionary from a subset of controlled dimensions to the initial low-cost values.
More info: <a class="reference external" href="https://microsoft.github.io/FLAML/docs/FAQ#about-low_cost_partial_config-in-tune">https://microsoft.github.io/FLAML/docs/FAQ#about-low_cost_partial_config-in-tune</a></p>
</dd>
<dt><strong>seed</strong><span class="classifier">Optional[int]</span></dt><dd><p>If provided, calls np.random.seed() with the provided value to set the seed globally at init.</p>
</dd>
</dl>
</dd>
<dt class="field-even">Attributes<span class="colon">:</span></dt>
<dd class="field-even"><dl class="simple">
<dt><code class="xref py py-obj docutils literal notranslate"><span class="pre">space_adapter</span></code></dt><dd><p>Get the space adapter instance (if any).</p>
</dd>
</dl>
</dd>
</dl>
<p class="rubric">Methods</p>
<table class="autosummary longtable docutils align-default">
<tbody>
<tr class="row-odd"><td><p><code class="xref py py-obj docutils literal notranslate"><span class="pre">cleanup</span></code>()</p></td>
<td><p>Cleanup the optimizer.</p></td>
</tr>
<tr class="row-even"><td><p><code class="xref py py-obj docutils literal notranslate"><span class="pre">get_best_observation</span></code>()</p></td>
<td><p>Returns the best observation so far as a dataframe.</p></td>
</tr>
<tr class="row-odd"><td><p><code class="xref py py-obj docutils literal notranslate"><span class="pre">get_observations</span></code>()</p></td>
<td><p>Returns the observations as a dataframe.</p></td>
</tr>
<tr class="row-even"><td><p><code class="xref py py-obj docutils literal notranslate"><span class="pre">register</span></code>(configurations, scores[, context])</p></td>
<td><p>Wrapper method, which employs the space adapter (if any), before registering the configurations and scores.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#mlos_core.optimizers.FlamlOptimizer.register_pending" title="mlos_core.optimizers.FlamlOptimizer.register_pending"><code class="xref py py-obj docutils literal notranslate"><span class="pre">register_pending</span></code></a>(configurations[, context])</p></td>
<td><p>Registers the given configurations as &quot;pending&quot;.</p></td>
</tr>
<tr class="row-even"><td><p><code class="xref py py-obj docutils literal notranslate"><span class="pre">suggest</span></code>([context, defaults])</p></td>
<td><p>Wrapper method, which employs the space adapter (if any), after suggesting a new configuration.</p></td>
</tr>
</tbody>
</table>
<dl class="py method">
<dt class="sig sig-object py" id="mlos_core.optimizers.FlamlOptimizer.register_pending">
<span class="sig-name descname"><span class="pre">register_pending</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">configurations</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">DataFrame</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">context</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">DataFrame</span><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><span class="pre">None</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">None</span></span></span><a class="headerlink" href="#mlos_core.optimizers.FlamlOptimizer.register_pending" title="Link to this definition">¶</a></dt>
<dd><p>Registers the given configurations as “pending”.
That is it say, it has been suggested by the optimizer, and an experiment trial has been started.
This can be useful for executing multiple trials in parallel, retry logic, etc.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><dl class="simple">
<dt><strong>configurations</strong><span class="classifier">pd.DataFrame</span></dt><dd><p>Dataframe of configurations / parameters. The columns are parameter names and the rows are the configurations.</p>
</dd>
<dt><strong>context</strong><span class="classifier">pd.DataFrame</span></dt><dd><p>Not Yet Implemented.</p>
</dd>
</dl>
</dd>
</dl>
</dd></dl>

</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="mlos_core.optimizers.OptimizerFactory">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">mlos_core.optimizers.</span></span><span class="sig-name descname"><span class="pre">OptimizerFactory</span></span><a class="headerlink" href="#mlos_core.optimizers.OptimizerFactory" title="Link to this definition">¶</a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">object</span></code></p>
<p>Simple factory class for creating BaseOptimizer-derived objects</p>
<p class="rubric">Methods</p>
<table class="autosummary longtable docutils align-default">
<tbody>
<tr class="row-odd"><td><p><a class="reference internal" href="../../generated/mlos_core.optimizers.OptimizerFactory.html#mlos_core.optimizers.OptimizerFactory.create" title="mlos_core.optimizers.OptimizerFactory.create"><code class="xref py py-obj docutils literal notranslate"><span class="pre">create</span></code></a>(*, parameter_space[, optimizer_type, ...])</p></td>
<td><p>Create a new optimizer instance, given the parameter space, optimizer type, and potential optimizer options.</p></td>
</tr>
</tbody>
</table>
<dl class="py method">
<dt class="sig sig-object py" id="mlos_core.optimizers.OptimizerFactory.create">
<em class="property"><span class="pre">static</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">create</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="o"><span class="pre">*</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">parameter_space</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">ConfigurationSpace</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">optimizer_type</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><a class="reference internal" href="../../generated/mlos_core.optimizers.OptimizerType.html#mlos_core.optimizers.OptimizerType" title="mlos_core.optimizers.OptimizerType"><span class="pre">OptimizerType</span></a></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">OptimizerType.FLAML</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">optimizer_kwargs</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">dict</span><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><span class="pre">None</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">space_adapter_type</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><a class="reference internal" href="../../generated/mlos_core.spaces.adapters.SpaceAdapterType.html#mlos_core.spaces.adapters.SpaceAdapterType" title="mlos_core.spaces.adapters.SpaceAdapterType"><span class="pre">SpaceAdapterType</span></a></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">SpaceAdapterType.IDENTITY</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">space_adapter_kwargs</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">dict</span><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><span class="pre">None</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">ConcreteOptimizer</span></span></span><a class="headerlink" href="#mlos_core.optimizers.OptimizerFactory.create" title="Link to this definition">¶</a></dt>
<dd><p>Create a new optimizer instance, given the parameter space, optimizer type,
and potential optimizer options.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><dl class="simple">
<dt><strong>parameter_space</strong><span class="classifier">ConfigSpace.ConfigurationSpace</span></dt><dd><p>Input configuration space.</p>
</dd>
<dt><strong>optimizer_type</strong><span class="classifier">OptimizerType</span></dt><dd><p>Optimizer class as defined by Enum.</p>
</dd>
<dt><strong>optimizer_kwargs</strong><span class="classifier">Optional[dict]</span></dt><dd><p>Optional arguments passed in Optimizer class constructor.</p>
</dd>
<dt><strong>space_adapter_type</strong><span class="classifier">Optional[SpaceAdapterType]</span></dt><dd><p>Space adapter class to be used alongside the optimizer.</p>
</dd>
<dt><strong>space_adapter_kwargs</strong><span class="classifier">Optional[dict]</span></dt><dd><p>Optional arguments passed in SpaceAdapter class constructor.</p>
</dd>
</dl>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><dl class="simple">
<dt><strong>optimizer</strong><span class="classifier">ConcreteOptimizer</span></dt><dd><p>Instance of concrete optimizer class
(e.g., RandomOptimizer, FlamlOptimizer, SmacOptimizer, etc.).</p>
</dd>
</dl>
</dd>
</dl>
</dd></dl>

</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="mlos_core.optimizers.RandomOptimizer">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">mlos_core.optimizers.</span></span><span class="sig-name descname"><span class="pre">RandomOptimizer</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="o"><span class="pre">*</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">parameter_space</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">ConfigurationSpace</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">space_adapter</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><a class="reference internal" href="../../generated/mlos_core.spaces.adapters.adapter.BaseSpaceAdapter.html#mlos_core.spaces.adapters.adapter.BaseSpaceAdapter" title="mlos_core.spaces.adapters.adapter.BaseSpaceAdapter"><span class="pre">BaseSpaceAdapter</span></a><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><span class="pre">None</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#mlos_core.optimizers.RandomOptimizer" title="Link to this definition">¶</a></dt>
<dd><p>Bases: <a class="reference internal" href="../../generated/mlos_core.optimizers.optimizer.BaseOptimizer.html#mlos_core.optimizers.optimizer.BaseOptimizer" title="mlos_core.optimizers.optimizer.BaseOptimizer"><code class="xref py py-class docutils literal notranslate"><span class="pre">BaseOptimizer</span></code></a></p>
<p>Optimizer class that produces random suggestions.
Useful for baseline comparison against Bayesian optimizers.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><dl class="simple">
<dt><strong>parameter_space</strong><span class="classifier">ConfigSpace.ConfigurationSpace</span></dt><dd><p>The parameter space to optimize.</p>
</dd>
</dl>
</dd>
<dt class="field-even">Attributes<span class="colon">:</span></dt>
<dd class="field-even"><dl class="simple">
<dt><code class="xref py py-obj docutils literal notranslate"><span class="pre">space_adapter</span></code></dt><dd><p>Get the space adapter instance (if any).</p>
</dd>
</dl>
</dd>
</dl>
<p class="rubric">Methods</p>
<table class="autosummary longtable docutils align-default">
<tbody>
<tr class="row-odd"><td><p><code class="xref py py-obj docutils literal notranslate"><span class="pre">cleanup</span></code>()</p></td>
<td><p>Cleanup the optimizer.</p></td>
</tr>
<tr class="row-even"><td><p><code class="xref py py-obj docutils literal notranslate"><span class="pre">get_best_observation</span></code>()</p></td>
<td><p>Returns the best observation so far as a dataframe.</p></td>
</tr>
<tr class="row-odd"><td><p><code class="xref py py-obj docutils literal notranslate"><span class="pre">get_observations</span></code>()</p></td>
<td><p>Returns the observations as a dataframe.</p></td>
</tr>
<tr class="row-even"><td><p><code class="xref py py-obj docutils literal notranslate"><span class="pre">register</span></code>(configurations, scores[, context])</p></td>
<td><p>Wrapper method, which employs the space adapter (if any), before registering the configurations and scores.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#mlos_core.optimizers.RandomOptimizer.register_pending" title="mlos_core.optimizers.RandomOptimizer.register_pending"><code class="xref py py-obj docutils literal notranslate"><span class="pre">register_pending</span></code></a>(configurations[, context])</p></td>
<td><p>Registers the given configurations as &quot;pending&quot;.</p></td>
</tr>
<tr class="row-even"><td><p><code class="xref py py-obj docutils literal notranslate"><span class="pre">suggest</span></code>([context, defaults])</p></td>
<td><p>Wrapper method, which employs the space adapter (if any), after suggesting a new configuration.</p></td>
</tr>
</tbody>
</table>
<dl class="py method">
<dt class="sig sig-object py" id="mlos_core.optimizers.RandomOptimizer.register_pending">
<span class="sig-name descname"><span class="pre">register_pending</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">configurations</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">DataFrame</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">context</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">DataFrame</span><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><span class="pre">None</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">None</span></span></span><a class="headerlink" href="#mlos_core.optimizers.RandomOptimizer.register_pending" title="Link to this definition">¶</a></dt>
<dd><p>Registers the given configurations as “pending”.
That is it say, it has been suggested by the optimizer, and an experiment trial has been started.
This can be useful for executing multiple trials in parallel, retry logic, etc.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><dl class="simple">
<dt><strong>configurations</strong><span class="classifier">pd.DataFrame</span></dt><dd><p>Dataframe of configurations / parameters. The columns are parameter names and the rows are the configurations.</p>
</dd>
<dt><strong>context</strong><span class="classifier">pd.DataFrame</span></dt><dd><p>Not Yet Implemented.</p>
</dd>
</dl>
</dd>
</dl>
</dd></dl>

</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="mlos_core.optimizers.SmacOptimizer">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">mlos_core.optimizers.</span></span><span class="sig-name descname"><span class="pre">SmacOptimizer</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="o"><span class="pre">*</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">parameter_space</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">ConfigurationSpace</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">space_adapter</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><a class="reference internal" href="../../generated/mlos_core.spaces.adapters.adapter.BaseSpaceAdapter.html#mlos_core.spaces.adapters.adapter.BaseSpaceAdapter" title="mlos_core.spaces.adapters.adapter.BaseSpaceAdapter"><span class="pre">BaseSpaceAdapter</span></a><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><span class="pre">None</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">seed</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">int</span><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><span class="pre">None</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">0</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">run_name</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">str</span><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><span class="pre">None</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">output_directory</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">str</span><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><span class="pre">None</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">max_trials</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">int</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">100</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">n_random_init</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">int</span><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><span class="pre">None</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">max_ratio</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">float</span><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><span class="pre">None</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">use_default_config</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">bool</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">n_random_probability</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">float</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">0.1</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#mlos_core.optimizers.SmacOptimizer" title="Link to this definition">¶</a></dt>
<dd><p>Bases: <a class="reference internal" href="mlos_core.optimizers.bayesian_optimizers.bayesian_optimizer.html#mlos_core.optimizers.bayesian_optimizers.bayesian_optimizer.BaseBayesianOptimizer" title="mlos_core.optimizers.bayesian_optimizers.bayesian_optimizer.BaseBayesianOptimizer"><code class="xref py py-class docutils literal notranslate"><span class="pre">BaseBayesianOptimizer</span></code></a></p>
<p>Wrapper class for SMAC based Bayesian optimization.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><dl class="simple">
<dt><strong>parameter_space</strong><span class="classifier">ConfigSpace.ConfigurationSpace</span></dt><dd><p>The parameter space to optimize.</p>
</dd>
<dt><strong>space_adapter</strong><span class="classifier">BaseSpaceAdapter</span></dt><dd><p>The space adapter class to employ for parameter space transformations.</p>
</dd>
<dt><strong>seed</strong><span class="classifier">Optional[int]</span></dt><dd><p>By default SMAC uses a known seed (0) to keep results reproducible.
However, if a <cite>None</cite> seed is explicitly provided, we let a random seed be produced by SMAC.</p>
</dd>
<dt><strong>run_name</strong><span class="classifier">Optional[str]</span></dt><dd><p>Name of this run. This is used to easily distinguish across different runs.
If set to <cite>None</cite> (default), SMAC will generate a hash from metadata.</p>
</dd>
<dt><strong>output_directory</strong><span class="classifier">Optional[str]</span></dt><dd><p>The directory where SMAC output will saved. If set to <cite>None</cite> (default), a temporary dir will be used.</p>
</dd>
<dt><strong>max_trials</strong><span class="classifier">int</span></dt><dd><p>Maximum number of trials (i.e., function evaluations) to be run. Defaults to 100.
Note that modifying this value directly affects the value of <cite>n_random_init</cite>, if latter is set to <cite>None</cite>.</p>
</dd>
<dt><strong>n_random_init</strong><span class="classifier">Optional[int]</span></dt><dd><p>Number of points evaluated at start to bootstrap the optimizer.
Default depends on max_trials and number of parameters and max_ratio.
Note: it can sometimes be useful to set this to 1 when pre-warming the
optimizer from historical data.
See Also: mlos_bench.optimizer.bulk_register</p>
</dd>
<dt><strong>max_ratio</strong><span class="classifier">Optional[int]</span></dt><dd><p>Maximum ratio of max_trials to be random configurations to be evaluated
at start to bootstrap the optimizer.
Useful if you want to explicitly control the number of random
configurations evaluated at start.</p>
</dd>
<dt><strong>use_default_config: bool</strong></dt><dd><p>Whether to use the default config for the first trial after random initialization.</p>
</dd>
<dt><strong>n_random_probability: float</strong></dt><dd><p>Probability of choosing to evaluate a random configuration during optimization.
Defaults to <cite>0.1</cite>. Setting this to a higher value favors exploration over exploitation.</p>
</dd>
</dl>
</dd>
<dt class="field-even">Attributes<span class="colon">:</span></dt>
<dd class="field-even"><dl class="simple">
<dt><a class="reference internal" href="#mlos_core.optimizers.SmacOptimizer.n_random_init" title="mlos_core.optimizers.SmacOptimizer.n_random_init"><code class="xref py py-obj docutils literal notranslate"><span class="pre">n_random_init</span></code></a></dt><dd><p>Gets the number of random samples to use to initialize the optimizer’s search space sampling.</p>
</dd>
<dt><code class="xref py py-obj docutils literal notranslate"><span class="pre">space_adapter</span></code></dt><dd><p>Get the space adapter instance (if any).</p>
</dd>
</dl>
</dd>
</dl>
<p class="rubric">Methods</p>
<table class="autosummary longtable docutils align-default">
<tbody>
<tr class="row-odd"><td><p><a class="reference internal" href="#mlos_core.optimizers.SmacOptimizer.acquisition_function" title="mlos_core.optimizers.SmacOptimizer.acquisition_function"><code class="xref py py-obj docutils literal notranslate"><span class="pre">acquisition_function</span></code></a>(configurations[, context])</p></td>
<td><p>Invokes the acquisition function from this Bayesian optimizer for the given configuration.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#mlos_core.optimizers.SmacOptimizer.cleanup" title="mlos_core.optimizers.SmacOptimizer.cleanup"><code class="xref py py-obj docutils literal notranslate"><span class="pre">cleanup</span></code></a>()</p></td>
<td><p>Cleanup the optimizer.</p></td>
</tr>
<tr class="row-odd"><td><p><code class="xref py py-obj docutils literal notranslate"><span class="pre">get_best_observation</span></code>()</p></td>
<td><p>Returns the best observation so far as a dataframe.</p></td>
</tr>
<tr class="row-even"><td><p><code class="xref py py-obj docutils literal notranslate"><span class="pre">get_observations</span></code>()</p></td>
<td><p>Returns the observations as a dataframe.</p></td>
</tr>
<tr class="row-odd"><td><p><code class="xref py py-obj docutils literal notranslate"><span class="pre">register</span></code>(configurations, scores[, context])</p></td>
<td><p>Wrapper method, which employs the space adapter (if any), before registering the configurations and scores.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#mlos_core.optimizers.SmacOptimizer.register_pending" title="mlos_core.optimizers.SmacOptimizer.register_pending"><code class="xref py py-obj docutils literal notranslate"><span class="pre">register_pending</span></code></a>(configurations[, context])</p></td>
<td><p>Registers the given configurations as &quot;pending&quot;.</p></td>
</tr>
<tr class="row-odd"><td><p><code class="xref py py-obj docutils literal notranslate"><span class="pre">suggest</span></code>([context, defaults])</p></td>
<td><p>Wrapper method, which employs the space adapter (if any), after suggesting a new configuration.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#mlos_core.optimizers.SmacOptimizer.surrogate_predict" title="mlos_core.optimizers.SmacOptimizer.surrogate_predict"><code class="xref py py-obj docutils literal notranslate"><span class="pre">surrogate_predict</span></code></a>(configurations[, context])</p></td>
<td><p>Obtain a prediction from this Bayesian optimizer's surrogate model for the given configuration(s).</p></td>
</tr>
</tbody>
</table>
<dl class="py method">
<dt class="sig sig-object py" id="mlos_core.optimizers.SmacOptimizer.acquisition_function">
<span class="sig-name descname"><span class="pre">acquisition_function</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">configurations</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">DataFrame</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">context</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">DataFrame</span><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><span class="pre">None</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">ndarray</span><span class="p"><span class="pre">[</span></span><span class="pre">Any</span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">dtype</span><span class="p"><span class="pre">[</span></span><span class="pre">_ScalarType_co</span><span class="p"><span class="pre">]</span></span><span class="p"><span class="pre">]</span></span></span></span><a class="headerlink" href="#mlos_core.optimizers.SmacOptimizer.acquisition_function" title="Link to this definition">¶</a></dt>
<dd><p>Invokes the acquisition function from this Bayesian optimizer for the given configuration.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><dl class="simple">
<dt><strong>configurations</strong><span class="classifier">pd.DataFrame</span></dt><dd><p>Dataframe of configurations / parameters. The columns are parameter names and the rows are the configurations.</p>
</dd>
<dt><strong>context</strong><span class="classifier">pd.DataFrame</span></dt><dd><p>Not Yet Implemented.</p>
</dd>
</dl>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="mlos_core.optimizers.SmacOptimizer.cleanup">
<span class="sig-name descname"><span class="pre">cleanup</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">None</span></span></span><a class="headerlink" href="#mlos_core.optimizers.SmacOptimizer.cleanup" title="Link to this definition">¶</a></dt>
<dd><p>Cleanup the optimizer.</p>
</dd></dl>

<dl class="py property">
<dt class="sig sig-object py" id="mlos_core.optimizers.SmacOptimizer.n_random_init">
<em class="property"><span class="pre">property</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">n_random_init</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="pre">int</span></em><a class="headerlink" href="#mlos_core.optimizers.SmacOptimizer.n_random_init" title="Link to this definition">¶</a></dt>
<dd><p>Gets the number of random samples to use to initialize the optimizer’s search space sampling.</p>
<p>Note: This may not be equal to the value passed to the initializer, due to logic present in the SMAC.
See Also: max_ratio</p>
<dl class="field-list simple">
<dt class="field-odd">Returns<span class="colon">:</span></dt>
<dd class="field-odd"><dl class="simple">
<dt>int</dt><dd><p>The number of random samples used to initialize the optimizer’s search space sampling.</p>
</dd>
</dl>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="mlos_core.optimizers.SmacOptimizer.register_pending">
<span class="sig-name descname"><span class="pre">register_pending</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">configurations</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">DataFrame</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">context</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">DataFrame</span><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><span class="pre">None</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">None</span></span></span><a class="headerlink" href="#mlos_core.optimizers.SmacOptimizer.register_pending" title="Link to this definition">¶</a></dt>
<dd><p>Registers the given configurations as “pending”.
That is it say, it has been suggested by the optimizer, and an experiment trial has been started.
This can be useful for executing multiple trials in parallel, retry logic, etc.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><dl class="simple">
<dt><strong>configurations</strong><span class="classifier">pd.DataFrame</span></dt><dd><p>Dataframe of configurations / parameters. The columns are parameter names and the rows are the configurations.</p>
</dd>
<dt><strong>context</strong><span class="classifier">pd.DataFrame</span></dt><dd><p>Not Yet Implemented.</p>
</dd>
</dl>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="mlos_core.optimizers.SmacOptimizer.surrogate_predict">
<span class="sig-name descname"><span class="pre">surrogate_predict</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">configurations</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">DataFrame</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">context</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">DataFrame</span><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><span class="pre">None</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">ndarray</span><span class="p"><span class="pre">[</span></span><span class="pre">Any</span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">dtype</span><span class="p"><span class="pre">[</span></span><span class="pre">_ScalarType_co</span><span class="p"><span class="pre">]</span></span><span class="p"><span class="pre">]</span></span></span></span><a class="headerlink" href="#mlos_core.optimizers.SmacOptimizer.surrogate_predict" title="Link to this definition">¶</a></dt>
<dd><p>Obtain a prediction from this Bayesian optimizer’s surrogate model for the given configuration(s).</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><dl class="simple">
<dt><strong>configurations</strong><span class="classifier">pd.DataFrame</span></dt><dd><p>Dataframe of configurations / parameters. The columns are parameter names and the rows are the configurations.</p>
</dd>
<dt><strong>context</strong><span class="classifier">pd.DataFrame</span></dt><dd><p>Not Yet Implemented.</p>
</dd>
</dl>
</dd>
</dl>
</dd></dl>

</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="mlos_core.optimizers.SpaceAdapterType">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">mlos_core.optimizers.</span></span><span class="sig-name descname"><span class="pre">SpaceAdapterType</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">value</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">names</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">*</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">module</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">qualname</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">type</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">start</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">1</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">boundary</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#mlos_core.optimizers.SpaceAdapterType" title="Link to this definition">¶</a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">Enum</span></code></p>
<p>Enumerate supported MlosCore space adapters.</p>
<dl class="py attribute">
<dt class="sig sig-object py" id="mlos_core.optimizers.SpaceAdapterType.IDENTITY">
<span class="sig-name descname"><span class="pre">IDENTITY</span></span><em class="property"><span class="w"> </span><span class="p"><span class="pre">=</span></span><span class="w"> </span><span class="pre">&lt;class</span> <span class="pre">'mlos_core.spaces.adapters.identity_adapter.IdentityAdapter'&gt;</span></em><a class="headerlink" href="#mlos_core.optimizers.SpaceAdapterType.IDENTITY" title="Link to this definition">¶</a></dt>
<dd><p>A no-op adapter will be used</p>
</dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="mlos_core.optimizers.SpaceAdapterType.LLAMATUNE">
<span class="sig-name descname"><span class="pre">LLAMATUNE</span></span><em class="property"><span class="w"> </span><span class="p"><span class="pre">=</span></span><span class="w"> </span><span class="pre">&lt;class</span> <span class="pre">'mlos_core.spaces.adapters.llamatune.LlamaTuneAdapter'&gt;</span></em><a class="headerlink" href="#mlos_core.optimizers.SpaceAdapterType.LLAMATUNE" title="Link to this definition">¶</a></dt>
<dd><p>An instance of LlamaTuneAdapter class will be used</p>
</dd></dl>

</dd></dl>

<section id="subpackages">
<h2>Subpackages<a class="headerlink" href="#subpackages" title="Link to this heading">¶</a></h2>
<div class="toctree-wrapper compound">
<ul>
<li class="toctree-l1"><a class="reference internal" href="mlos_core.optimizers.bayesian_optimizers.html">mlos_core.optimizers.bayesian_optimizers package</a><ul>
<li class="toctree-l2"><a class="reference internal" href="mlos_core.optimizers.bayesian_optimizers.html#mlos_core.optimizers.bayesian_optimizers.BaseBayesianOptimizer"><code class="docutils literal notranslate"><span class="pre">BaseBayesianOptimizer</span></code></a><ul>
<li class="toctree-l3"><a class="reference internal" href="mlos_core.optimizers.bayesian_optimizers.html#mlos_core.optimizers.bayesian_optimizers.BaseBayesianOptimizer.acquisition_function"><code class="docutils literal notranslate"><span class="pre">BaseBayesianOptimizer.acquisition_function()</span></code></a></li>
<li class="toctree-l3"><a class="reference internal" href="mlos_core.optimizers.bayesian_optimizers.html#mlos_core.optimizers.bayesian_optimizers.BaseBayesianOptimizer.surrogate_predict"><code class="docutils literal notranslate"><span class="pre">BaseBayesianOptimizer.surrogate_predict()</span></code></a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="mlos_core.optimizers.bayesian_optimizers.html#mlos_core.optimizers.bayesian_optimizers.SmacOptimizer"><code class="docutils literal notranslate"><span class="pre">SmacOptimizer</span></code></a><ul>
<li class="toctree-l3"><a class="reference internal" href="mlos_core.optimizers.bayesian_optimizers.html#mlos_core.optimizers.bayesian_optimizers.SmacOptimizer.acquisition_function"><code class="docutils literal notranslate"><span class="pre">SmacOptimizer.acquisition_function()</span></code></a></li>
<li class="toctree-l3"><a class="reference internal" href="mlos_core.optimizers.bayesian_optimizers.html#mlos_core.optimizers.bayesian_optimizers.SmacOptimizer.cleanup"><code class="docutils literal notranslate"><span class="pre">SmacOptimizer.cleanup()</span></code></a></li>
<li class="toctree-l3"><a class="reference internal" href="mlos_core.optimizers.bayesian_optimizers.html#mlos_core.optimizers.bayesian_optimizers.SmacOptimizer.n_random_init"><code class="docutils literal notranslate"><span class="pre">SmacOptimizer.n_random_init</span></code></a></li>
<li class="toctree-l3"><a class="reference internal" href="mlos_core.optimizers.bayesian_optimizers.html#mlos_core.optimizers.bayesian_optimizers.SmacOptimizer.register_pending"><code class="docutils literal notranslate"><span class="pre">SmacOptimizer.register_pending()</span></code></a></li>
<li class="toctree-l3"><a class="reference internal" href="mlos_core.optimizers.bayesian_optimizers.html#mlos_core.optimizers.bayesian_optimizers.SmacOptimizer.surrogate_predict"><code class="docutils literal notranslate"><span class="pre">SmacOptimizer.surrogate_predict()</span></code></a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="mlos_core.optimizers.bayesian_optimizers.html#submodules">Submodules</a><ul>
<li class="toctree-l3"><a class="reference internal" href="mlos_core.optimizers.bayesian_optimizers.bayesian_optimizer.html">mlos_core.optimizers.bayesian_optimizers.bayesian_optimizer module</a><ul>
<li class="toctree-l4"><a class="reference internal" href="mlos_core.optimizers.bayesian_optimizers.bayesian_optimizer.html#mlos_core.optimizers.bayesian_optimizers.bayesian_optimizer.BaseBayesianOptimizer"><code class="docutils literal notranslate"><span class="pre">BaseBayesianOptimizer</span></code></a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="mlos_core.optimizers.bayesian_optimizers.smac_optimizer.html">mlos_core.optimizers.bayesian_optimizers.smac_optimizer module</a><ul>
<li class="toctree-l4"><a class="reference internal" href="mlos_core.optimizers.bayesian_optimizers.smac_optimizer.html#mlos_core.optimizers.bayesian_optimizers.smac_optimizer.SmacOptimizer"><code class="docutils literal notranslate"><span class="pre">SmacOptimizer</span></code></a></li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
</ul>
</div>
</section>
<section id="submodules">
<h2>Submodules<a class="headerlink" href="#submodules" title="Link to this heading">¶</a></h2>
<div class="toctree-wrapper compound">
<ul>
<li class="toctree-l1"><a class="reference internal" href="mlos_core.optimizers.flaml_optimizer.html">mlos_core.optimizers.flaml_optimizer module</a><ul>
<li class="toctree-l2"><a class="reference internal" href="mlos_core.optimizers.flaml_optimizer.html#mlos_core.optimizers.flaml_optimizer.EvaluatedSample"><code class="docutils literal notranslate"><span class="pre">EvaluatedSample</span></code></a><ul>
<li class="toctree-l3"><a class="reference internal" href="mlos_core.optimizers.flaml_optimizer.html#mlos_core.optimizers.flaml_optimizer.EvaluatedSample.config"><code class="docutils literal notranslate"><span class="pre">EvaluatedSample.config</span></code></a></li>
<li class="toctree-l3"><a class="reference internal" href="mlos_core.optimizers.flaml_optimizer.html#mlos_core.optimizers.flaml_optimizer.EvaluatedSample.score"><code class="docutils literal notranslate"><span class="pre">EvaluatedSample.score</span></code></a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="mlos_core.optimizers.flaml_optimizer.html#mlos_core.optimizers.flaml_optimizer.FlamlOptimizer"><code class="docutils literal notranslate"><span class="pre">FlamlOptimizer</span></code></a><ul>
<li class="toctree-l3"><a class="reference internal" href="mlos_core.optimizers.flaml_optimizer.html#mlos_core.optimizers.flaml_optimizer.FlamlOptimizer.register_pending"><code class="docutils literal notranslate"><span class="pre">FlamlOptimizer.register_pending()</span></code></a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="mlos_core.optimizers.optimizer.html">mlos_core.optimizers.optimizer module</a><ul>
<li class="toctree-l2"><a class="reference internal" href="mlos_core.optimizers.optimizer.html#mlos_core.optimizers.optimizer.BaseOptimizer"><code class="docutils literal notranslate"><span class="pre">BaseOptimizer</span></code></a><ul>
<li class="toctree-l3"><a class="reference internal" href="mlos_core.optimizers.optimizer.html#mlos_core.optimizers.optimizer.BaseOptimizer.cleanup"><code class="docutils literal notranslate"><span class="pre">BaseOptimizer.cleanup()</span></code></a></li>
<li class="toctree-l3"><a class="reference internal" href="mlos_core.optimizers.optimizer.html#mlos_core.optimizers.optimizer.BaseOptimizer.get_best_observation"><code class="docutils literal notranslate"><span class="pre">BaseOptimizer.get_best_observation()</span></code></a></li>
<li class="toctree-l3"><a class="reference internal" href="mlos_core.optimizers.optimizer.html#mlos_core.optimizers.optimizer.BaseOptimizer.get_observations"><code class="docutils literal notranslate"><span class="pre">BaseOptimizer.get_observations()</span></code></a></li>
<li class="toctree-l3"><a class="reference internal" href="mlos_core.optimizers.optimizer.html#mlos_core.optimizers.optimizer.BaseOptimizer.register"><code class="docutils literal notranslate"><span class="pre">BaseOptimizer.register()</span></code></a></li>
<li class="toctree-l3"><a class="reference internal" href="mlos_core.optimizers.optimizer.html#mlos_core.optimizers.optimizer.BaseOptimizer.register_pending"><code class="docutils literal notranslate"><span class="pre">BaseOptimizer.register_pending()</span></code></a></li>
<li class="toctree-l3"><a class="reference internal" href="mlos_core.optimizers.optimizer.html#mlos_core.optimizers.optimizer.BaseOptimizer.space_adapter"><code class="docutils literal notranslate"><span class="pre">BaseOptimizer.space_adapter</span></code></a></li>
<li class="toctree-l3"><a class="reference internal" href="mlos_core.optimizers.optimizer.html#mlos_core.optimizers.optimizer.BaseOptimizer.suggest"><code class="docutils literal notranslate"><span class="pre">BaseOptimizer.suggest()</span></code></a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="mlos_core.optimizers.random_optimizer.html">mlos_core.optimizers.random_optimizer module</a><ul>
<li class="toctree-l2"><a class="reference internal" href="mlos_core.optimizers.random_optimizer.html#mlos_core.optimizers.random_optimizer.RandomOptimizer"><code class="docutils literal notranslate"><span class="pre">RandomOptimizer</span></code></a><ul>
<li class="toctree-l3"><a class="reference internal" href="mlos_core.optimizers.random_optimizer.html#mlos_core.optimizers.random_optimizer.RandomOptimizer.register_pending"><code class="docutils literal notranslate"><span class="pre">RandomOptimizer.register_pending()</span></code></a></li>
</ul>
</li>
</ul>
</li>
</ul>
</div>
</section>
</section>


           </div>
          </div>
          <footer><div class="rst-footer-buttons" role="navigation" aria-label="Footer">
        <a href="mlos_core.html" class="btn btn-neutral float-left" title="mlos_core package" accesskey="p" rel="prev"><span class="fa fa-arrow-circle-left" aria-hidden="true"></span> Previous</a>
        <a href="mlos_core.optimizers.bayesian_optimizers.html" class="btn btn-neutral float-right" title="mlos_core.optimizers.bayesian_optimizers package" accesskey="n" rel="next">Next <span class="fa fa-arrow-circle-right" aria-hidden="true"></span></a>
    </div>

  <hr/>

  <div role="contentinfo">
    <p>&#169; Copyright 2022, GSL.</p>
  </div>

  Built with <a href="https://www.sphinx-doc.org/">Sphinx</a> using a
    <a href="https://github.com/readthedocs/sphinx_rtd_theme">theme</a>
    provided by <a href="https://readthedocs.org">Read the Docs</a>.
   

</footer>
        </div>
      </div>
    </section>
  </div>
  <script>
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script> 

</body>
</html>